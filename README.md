# Spotify Data Pipeline using Spark, AWS and Snowflake

## Table of Contents

1. [About The Project](#about-the-project)
   - [Built With](#built-with)
2. [Getting Started](#getting-started)
   - [Prerequisites](#prerequisites)
   - [Installation](#installation)
3. [Usage](#usage)
4. [References](#references)
5. [Contact](#contact)

---

## About The Project

This project is an excellent opportunity for anyone looking to apply their knowledge of Python, AWS, and data
engineering concepts, particularly with real-world applications like data extraction and processing from APIs.
The Ultimate Goal of the Project is that everyone should know how the Data Pipeline works to Extract, Transform and load the 
data to Database/Api's from where it can be consumed and used for Bussiness Process.

### Topics Implemented:
- Data Extraction
- Data Transformation
- Data Loading
- Power BI DashBoard

---

## Built With

The tools that have been used in the project are:

- **MLflow**
- **DagsHub**
- **Docker**
- **AWS S3**
- **AWS EC2**

---

## Getting Started

### Introduction

In today’s data-driven world, businesses leverage insights from large datasets to make informed decisions. In this Projest,I have implemented an automated end-to-end Spotify data pipeline using Python, Apache Spark, and AWS.

The pipeline will extract data from Spotify’s Top 50 global playlist using the Spotify API, transform it with Apache Spark, and load it into Snowflake for analysis. From extracting song, artist, and album data using Python to processing and storing the results on AWS. Whether you’re looking to apply your knowledge of Python and Apache Spark or gain practical experience in data engineering, this project will provide you with hands-on insights into building scalable data pipelines.


![Spotify Data Pipeline using Spark, AWS and Snowflake](./assets/AWS%20Lambda%20(Data%20Extraction).png)

### Prerequisites

- **Python 3.7+**
- **Git** 
- **AWS Account**
- **Knowledge of python library**
- **Apache Spark**

### Installation

1. **Download Python Packages**  
2. **Spotify Developer Package**
3. **Snowflake Connecter**

### Usage
1. **Automation of the Data Processing**<br>
    --Automates the process of extracting, transforming, and loading (ETL).<br>
    --Reduced Manual Intervention.<br>
2. **Scalability**<br>
    --Handling Large Data Volumes<br>
    --Parallel Execution<br>
3. **Cost Efficiency**<br>
     --Operational Efficiency<br>
     --Resource Optimization<br>

### References
1. [https://medium.com/@halfcapsule/understanding-data-pipelines-architecture-and-workflow-4f7ab1e864e6](https://medium.com/@halfcapsule/understanding-data-pipelines-architecture-and-workflow-4f7ab1e864e6)
2. [https://medium.com/the-data-experience/building-a-data-pipeline-from-scratch-32b712cfb1db](https://medium.com/the-data-experience/building-a-data-pipeline-from-scratch-32b712cfb1db)

### Contact
### _Pramathesh T S_

**Email ID** - pramatheshts025@gmail.com<br>
**LinkedIn** - [https://www.linkedin.com/in/pramatheshts1999/](https://www.linkedin.com/in/pramatheshts1999/)<br>
**GitHub**   - [https://github.com/Pramathesh690/](https://github.com/Pramathesh690/)

